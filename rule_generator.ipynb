{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate Rules that pin top selling items & Boost Top Categories\n",
    "\n",
    "## Requirments\n",
    "\n",
    "* Will need to have an index with records that include category. \n",
    "* You will need to create an export of categories using browse end-point\n",
    "* Will need to have historical analytics data that has the following fields. \n",
    "    1. query\n",
    "    2. record\n",
    "    3. position (rank)\n",
    "* If you don't want to boost category then you can skip the part where we import category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set all the necessary configs\n",
    "#API_KEY has to be admin/write\n",
    "\n",
    "INDEX_NAME = \"Variants\"\n",
    "APP_ID = \"\"\n",
    "API_KEY = \"\"\n",
    "ANALYTICS_FILE = \"boost.csv\"\n",
    "CATEGORIES_FILE = \"category_export.json\"\n",
    "BATCH_SIZE = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and initiate algolia index\n",
    "from algoliasearch.search_client import SearchClient\n",
    "import csv\n",
    "\n",
    "client = SearchClient.create(APP_ID, API_KEY)\n",
    "\n",
    "\n",
    "# Create a new index and add a record\n",
    "index = client.init_index(INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will check to see if a string contains special characters.\n",
    "# we need to do this in-order to make sure that the queries we add to rules are valid\n",
    "import re\n",
    "\n",
    "# Function checks if the string\n",
    "# contains any special character\n",
    "\n",
    "def run(input_string):\n",
    "    pattern = r'^[a-zA-Z0-9\\s]+$'\n",
    "    return bool(re.match(pattern, input_string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics File Breakdown\n",
    "\n",
    "The analytics file export will look something like this: \n",
    "\n",
    "| query | Record | position |\n",
    "------------------------------\n",
    "| honey | obj123 | 1 |\n",
    "| honey | obj124 | 2 |\n",
    "| honey | obj125 | 3 |\n",
    "| milk | obj126 | 1 |\n",
    "| milk | obj127 | 2 |\n",
    "| milk | obj128 | 3 |\n",
    "-----------------------------\n",
    "\n",
    "The goal will be to create a rule with the following config\n",
    "\n",
    "Rule 1: \n",
    "condition: \n",
    "    query: honey\n",
    "consequence:\n",
    "    pin: \n",
    "        obj123: 1\n",
    "        obj124: 2\n",
    "        obj125: 3\n",
    "    boost: \n",
    "        honey category\n",
    "\n",
    "Rule 2: \n",
    "condition: \n",
    "    query: milk\n",
    "consequence:\n",
    "    pin: \n",
    "        obj126: 1\n",
    "        obj127: 2\n",
    "        obj128: 3\n",
    "    boost: \n",
    "        milk category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the analytics file and add the records into an array\n",
    "list_of_terms = []\n",
    "with open(ANALYTICS_FILE, \"r\") as data:\n",
    "    new_data = csv.DictReader(data, delimiter=',')\n",
    "    for d in new_data:\n",
    "        list_of_terms.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this next function will loop through the list_of_terms\n",
    "# and create an object where the key is the query and value is an object with the necessary data for the rule\n",
    "\n",
    "# SKU = objectId\n",
    "# Suggested Rank = Position\n",
    "\n",
    "# Region is commented out because in my test case region was a secondary condition. \n",
    "\n",
    "proper_list = {}\n",
    "for term_obj in list_of_terms:\n",
    "    sku = term_obj[\"SKU\"]\n",
    "    query = term_obj[\"Query\"]\n",
    "    if not run(query):\n",
    "        continue\n",
    "    #region = term_obj[\"Region\"]\n",
    "    #query_region = query + \"_\" + region\n",
    "    new_obj = {\n",
    "        \"query\": query,\n",
    "        \"sku\": sku,\n",
    "        \"position\": term_obj[\"Suggested Rank\"],\n",
    "   ##     \"region\": region\n",
    "    }\n",
    "    if query not in proper_list:\n",
    "        proper_list[query] = [new_obj]\n",
    "    else:\n",
    "        proper_list[query].append(new_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next function will create the rules object and add them to an array called list_of_rules\n",
    "# I use the hash function to create the objectID for the rule. \n",
    "\n",
    "list_of_rules = []\n",
    "for key, value in proper_list.items():\n",
    "    rule_obj = {}\n",
    "    rule_obj[\"objectID\"] = str(hash(key))\n",
    "    rule_obj[\"conditions\"] = [\n",
    "        {\n",
    "            \"pattern\": key,\n",
    "            \"anchoring\": 'is',\n",
    "            \"alternatives\": True\n",
    "        \n",
    "        },\n",
    "    ]\n",
    "    consequences = []\n",
    "    for skus in value:\n",
    "        promote = {\n",
    "            \"objectID\": skus[\"sku\"],\n",
    "            \"position\": int(skus[\"position\"]) - 1\n",
    "        }\n",
    "        if any(obj[\"objectID\"] == skus[\"sku\"] for obj in consequences):\n",
    "            continue\n",
    "        consequences.append(promote)\n",
    "    rule_obj[\"consequence\"] = {\"promote\": consequences, \"filterPromotes\": True}\n",
    "    list_of_rules.append(rule_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now import the categories export\n",
    "# if we don't want to boost categories you can skip the next two. \n",
    "\n",
    "import json\n",
    "with open(CATEGORIES_FILE, \"r\") as import_file:\n",
    "    categories = json.load(import_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take the list of categories and the list of rules\n",
    "# find the category that belongs to the top pinned item\n",
    "# once it does that it will add it as consequence. optionalFilters in rules need to be enabled for the App. \n",
    "# this might take some time to run. Not fully optimized\n",
    "\n",
    "def get_lowest_position_category(objects_list, categories_list):\n",
    "    for obj in objects_list:\n",
    "        lowest_position = float('inf')\n",
    "        lowest_position_category = None\n",
    "        promote_list = obj.get(\"consequence\", {}).get(\"promote\", [])\n",
    "        for promote_item in promote_list:\n",
    "            position = promote_item.get(\"position\", 0)\n",
    "            if position < lowest_position:\n",
    "                lowest_position = position\n",
    "                object_id = promote_item.get(\"objectID\")\n",
    "                for category in categories_list:\n",
    "                    if category.get(\"objectID\") == object_id:\n",
    "                        lowest_position_category = category.get(\"Category\")\n",
    "                        break\n",
    "        if lowest_position_category:\n",
    "            obj[\"consequence\"][\"params\"] = {\n",
    "                \"optionalFilters\": \"Category:\"+lowest_position_category}\n",
    "    return objects_list\n",
    "\n",
    "# run the function\n",
    "list_of_rules = get_lowest_position_category(list_of_rules, categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batches to send the rules to algolia. This will allow us to use a try / catch to monitor sends.\n",
    "# you can either increase/decrease the batch size\n",
    "\n",
    "def create_batches(input_array):\n",
    "    batch_size = BATCH_SIZE\n",
    "    num_batches = len(input_array) // batch_size\n",
    "    remainder = len(input_array) % batch_size\n",
    "\n",
    "    batches = [input_array[i*batch_size:(i+1)*batch_size]\n",
    "               for i in range(num_batches)]\n",
    "    if remainder > 0:\n",
    "        batches.append(input_array[num_batches*batch_size:])\n",
    "\n",
    "    return batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the create function\n",
    "batches = create_batches(list_of_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will save the rules into your algolia index\n",
    "for batch in batches:\n",
    "    try:\n",
    "        index.save_rules(batch)\n",
    "    except Exception as error:\n",
    "        print(error)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93adaf446d780bde2238b484185c78f423f2d5261886064f85b045e8934dc039"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit ('3.10.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
